Recent years have seen development of Large Language Models (LLMs). Significant advancements have been made in natural language processing (NLP), reasoning, and creative activities by OpenAI's ChatGPT, Google's Gemini, and Anthropic's Claude. But the pace at which the landscape is changing is unparalleled. The 2021 AI100 paper [1] included a summary of the development of AI, but it could not foresee the influence of LLMs, which have since changed daily life, especially education. The impressive talents of GPT-4, ranging from coding to creative writing, are highlighted in the 2023 study by Bubeck et al. [2], highlighting the rapid advancement of AI. 

Less than 14 days ago, DeepSeek R1 was launched, outperforming ChatGPT in several benchmarks. This breakthrough has encouraged several posts on platforms like LinkedIn, even a post drawing parallels between ChatGPT and Blackberry, a mobile company eventually overtaken by more innovative competitors and how their,  BlackBerry and ChatGPT alike, most prosperous periods happened right at the beginning of new innovation. According to the DeepSeek R1 paper [3], this model outperformed Claude-3.5-Sonnet, GPT-4o, and other leading models in reasoning, coding, and math tasks, demonstrating that LLMs still have significant room for improvement. Another impressive fact that DeepSeek R1 brought to light was how economically it can be to develop a LLM which cost a fraction of the price it took to make ChatGPT. 

It is clear that academics will continue to examine the possibilities and constraints of LLMs, despite the fact that it is hard to predict the future of AI. Given the rapid advancement in basic research, I believe the next big step will be the integration of LLMs into Embodied AI Systems, which are robotic systems that can see, think, and act in physical surroundings. This integration will increase the usability and accessibility of humanoid robots by bridging the gap between language comprehension and real-world interaction.

Present-day LLMs are very good at processing and producing text, but they can't engage with the real world. We can develop AI systems that comprehend language and apply it to carry out tasks in real-world situations by integrating LLMs into robots. For instance, by comprehending spoken commands, organising procedures, and carrying them out with robotic arms or mobility devices, an embodied AI system driven by an LLM may help with domestic tasks like cooking or cleaning. Multimodal learning, in which LLMs are taught on material that incorporates text, visual, aural, and sensory inputs, will propel this development.

In conclusion, LLMs will probably be incorporated into embodied AI systems during the course of the next two years, which would be a major turning point in the development of AI. Although these technologies have enormous potential to change society, their effectiveness will rely on our capacity to resolve the moral and practical issues that arise. By taking proactive measures to resolve these problems, we can use embodied AI to build a more inventive and just future.
